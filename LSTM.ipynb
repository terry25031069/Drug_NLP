{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, re, shutil\n",
    "import json\n",
    "import jieba, numpy\n",
    "import string, gensim\n",
    "import threading\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from gensim.models.doc2vec import Doc2Vec\n",
    "from collections import Counter\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_jfull(filename: str):\n",
    "    with open(os.path.join(dirpath + '/drug_case', filename), \"r\", encoding = 'UTF-8') as f:\n",
    "        data = json.load(f)['JFULL']\n",
    "        data = data.replace(' ', '').replace('　', '')\n",
    "    target0 = data.find('主文\\r\\n')\n",
    "    # 如果案字帶有秩的，代表為社會秩序維護法的案子，並不在我們的管理範圍內\n",
    "    if \"秩\" in filename: \n",
    "        return \"\"\n",
    "    \n",
    "    # 如果 JFULL 找不到主文，那就代表是 pdf 檔案\n",
    "    # 暫定不處置\n",
    "    if target0 != -1:\n",
    "        target1 = []\n",
    "        if data.find('事實及理由\\r\\n') != -1:\n",
    "            target1.append(data.find('事實及理由\\r\\n', target0))\n",
    "        if data.find('犯罪事實\\r\\n') != -1:\n",
    "            target1.append(data.find('犯罪事實\\r\\n', target0))\n",
    "        if data.find('理由\\r\\n') != -1:\n",
    "            target1.append(data.find('理由\\r\\n', target0))\n",
    "        if data.find('事實\\r\\n') != -1:\n",
    "            target1.append(data.find('事實\\r\\n', target0))\n",
    "        if data.find('中華民國') != -1:\n",
    "            target1.append(data.find('中華民國', target0))\n",
    "        target1 = min(target1)\n",
    "\n",
    "        data = data[target1:].replace('\\r\\n', '')\n",
    "        data = re.split(r'[，。「」（）『』【】；：、]', data)\n",
    "        return data\n",
    "    else:\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24669/24669 [00:27<00:00, 884.98it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24669, 300) (24669,)\n",
      "['犯罪事實一', '郭權葳基於施用第一', '二級毒品之犯意', '於民國108年11月20日12時許', '在彰化縣鹿港鎮臺17線附近', '於其使用之汽車內', '以將海洛因與甲基安非他命置入玻璃球管內', '再以火焰燒灼玻璃球管', '使其內海洛因與甲基安非他命轉化為煙霧狀後', '以口鼻吸食之方式', '同時施用第一級毒品海洛因與第二級毒品甲基安非他命1次', '嗣於108年11月21日0時5分許', '在彰化縣鹿港鎮永康路與永寧街98巷口', '因毒品通緝案件為警查獲', '並扣得第一級毒品海洛因3包', '驗餘淨重共2.87公克', '', '第二級毒品甲基安非他命1包', '驗餘淨重1.1325公克', '', '殘渣袋1批', '分裝袋1批及塑膠鏟管5支等物', '經警採集其尿液送驗', '結果呈嗎啡', '可待因', '安非他命及甲基安非他命陽性反應', '二', '案經彰化縣警察局鹿港分局報告臺灣彰化地方檢察署檢察官偵查起訴', '理由一', '上開犯罪事實', '業經被告郭權葳於本院準備', '審理程序時坦承不諱', '且有搜索扣押筆錄', '扣押物品目錄表', '房屋租賃契約書', '蒐證照片', '扣案物照片', '毒品初步檢驗報告單', '彰化縣警察局鹿港分局尿液代號與真實姓名對照認證單', '臺灣檢驗科技股份有限公司出具之濫用藥物檢驗報告', '扣案之海洛因3包', '甲基安非他命1包', '塑膠剷管5支', '殘渣袋1組', '分裝袋1組', '法務部調查局濫用藥物實驗室鑑定書', '衛生福利部草屯療養院鑑驗書在卷可以佐證', '足見被告前揭任意性自白與事實相符', '從而', '本案事證明確', '應依法論科', '二', '核被告所為係犯毒品危害防制條例第10條第1項之施用第一級毒品罪及同條第2項之施用第二級毒品罪', '被告為施用毒品而持有第一', '二級毒品', '其持有之低度行為均應為施用之高度行為所吸收', '均不另論罪', '又被告於上開時', '地', '同時施用第一', '二級毒品', '係以一行為觸犯施用第一級毒品及施用第二級毒品2罪', '為想像競合犯', '應從一重論以施用第一級毒品罪', '三', '本件被告已為認罪之表示', '且經檢察官與被告於審判外達成協商之合意', '合意內容如主文所示', '上開協商合意並無刑事訴訟法第455條之4第1項所列各款情形', '業經本院於踐行同法第455條之3第1項之告知程序後', '訊問調查屬實', '檢察官聲請改依協商程序而為判決', '本院爰不經言詞辯論', '於協商合意範圍內為協商判決', '四', '扣案之如附表所示之海洛因3包及甲基安非他命1包', '為第一級', '第二級毒品', '應依毒品危害防制條例第18條第1項前段之規定', '沒收銷燬', '扣案之毒品殘渣袋1組', '塑膠剷管5支', '分裝袋1組', '為被告所有供本案犯罪所用之物', '業據被告供承在卷', '爰依刑法第38條第2項規定沒收', '五', '應適用之法條', '刑事訴訟法第273條之1第1項', '第455條之4第2項', '六', '協商判決除有刑事訴訟法第455條之4第1項第1款於本訊問程序終結前', '被告撤銷協商合意或檢察官撤回協商聲請者', '第2款被告協商之意思非出於自由意志者', '第4款被告所犯之罪非第455條之2第1項所定得以協商判決者', '第6款被告有其他較重之裁判上一罪之犯罪事實者', '第7款法院認應諭知免刑或免訴', '不受理者情形之一', '及違反同條第2項', '法院應於協商合意範圍內為判決', '法院為協商判決所科之刑', '以宣告緩刑或二年以下有期徒刑', '拘役或罰金為限', '之規定者外', '不得上訴', '七', '如不服本件判決', '且符合前述得上訴之特別規定者', '得自收受判決送達之日起20日內', '向本院提出上訴書狀', '上訴於第二審法院', '中華民國109年2月25日刑事第七庭法官陳怡潔以上正本證明與原本無異', '中華民國109年2月25日書記官顧嘉文┌─────────────────────────┐│附表│├──┬───────┬──────────────┤│編號│扣案物│數量', '重量', '│├──┼───────┼──────────────┤│1│海洛因│1包', '驗餘淨重0.87公克', '│├──┼───────┼──────────────┤│2│海洛因│2包', '驗餘淨重共2公克', '│├──┼───────┼──────────────┤│3│安非他命│1包', '驗餘淨重1.1325公克', '│├──┼───────┼──────────────┤│4│毒品殘渣袋│1組│├──┼───────┼──────────────┤│5│塑膠剷管│5支│├──┼───────┼──────────────┤│6│分裝袋│1組│└──┴───────┴──────────────┘', '犯罪事實一', '郭權葳基於施用第一', '二級毒品之犯意', '於民國108年11月20日12時許', '在彰化縣鹿港鎮臺17線附近', '於其使用之汽車內', '以將海洛因與甲基安非他命置入玻璃球管內', '再以火焰燒灼玻璃球管', '使其內海洛因與甲基安非他命轉化為煙霧狀後', '以口鼻吸食之方式', '同時施用第一級毒品海洛因與第二級毒品甲基安非他命1次', '嗣於108年11月21日0時5分許', '在彰化縣鹿港鎮永康路與永寧街98巷口', '因毒品通緝案件為警查獲', '並扣得第一級毒品海洛因3包', '驗餘淨重共2.87公克', '', '第二級毒品甲基安非他命1包', '驗餘淨重1.1325公克', '', '殘渣袋1批', '分裝袋1批及塑膠鏟管5支等物', '經警採集其尿液送驗', '結果呈嗎啡', '可待因', '安非他命及甲基安非他命陽性反應', '二', '案經彰化縣警察局鹿港分局報告臺灣彰化地方檢察署檢察官偵查起訴', '理由一', '上開犯罪事實', '業經被告郭權葳於本院準備', '審理程序時坦承不諱', '且有搜索扣押筆錄', '扣押物品目錄表', '房屋租賃契約書', '蒐證照片', '扣案物照片', '毒品初步檢驗報告單', '彰化縣警察局鹿港分局尿液代號與真實姓名對照認證單', '臺灣檢驗科技股份有限公司出具之濫用藥物檢驗報告', '扣案之海洛因3包', '甲基安非他命1包', '塑膠剷管5支', '殘渣袋1組', '分裝袋1組', '法務部調查局濫用藥物實驗室鑑定書', '衛生福利部草屯療養院鑑驗書在卷可以佐證', '足見被告前揭任意性自白與事實相符', '從而', '本案事證明確', '應依法論科', '二', '核被告所為係犯毒品危害防制條例第10條第1項之施用第一級毒品罪及同條第2項之施用第二級毒品罪', '被告為施用毒品而持有第一', '二級毒品', '其持有之低度行為均應為施用之高度行為所吸收', '均不另論罪', '又被告於上開時', '地', '同時施用第一', '二級毒品', '係以一行為觸犯施用第一級毒品及施用第二級毒品2罪', '為想像競合犯', '應從一重論以施用第一級毒品罪', '三', '本件被告已為認罪之表示', '且經檢察官與被告於審判外達成協商之合意', '合意內容如主文所示', '上開協商合意並無刑事訴訟法第455條之4第1項所列各款情形', '業經本院於踐行同法第455條之3第1項之告知程序後', '訊問調查屬實', '檢察官聲請改依協商程序而為判決', '本院爰不經言詞辯論', '於協商合意範圍內為協商判決', '四', '扣案之如附表所示之海洛因3包及甲基安非他命1包', '為第一級', '第二級毒品', '應依毒品危害防制條例第18條第1項前段之規定', '沒收銷燬', '扣案之毒品殘渣袋1組', '塑膠剷管5支', '分裝袋1組', '為被告所有供本案犯罪所用之物', '業據被告供承在卷', '爰依刑法第38條第2項規定沒收', '五', '應適用之法條', '刑事訴訟法第273條之1第1項', '第455條之4第2項', '六', '協商判決除有刑事訴訟法第455條之4第1項第1款於本訊問程序終結前', '被告撤銷協商合意或檢察官撤回協商聲請者', '第2款被告協商之意思非出於自由意志者', '第4款被告所犯之罪非第455條之2第1項所定得以協商判決者', '第6款被告有其他較重之裁判上一罪之犯罪事實者', '第7款法院認應諭知免刑或免訴', '不受理者情形之一', '及違反同條第2項', '法院應於協商合意範圍內為判決', '法院為協商判決所科之刑', '以宣告緩刑或二年以下有期徒刑', '拘役或罰金為限', '之規定者外', '不得上訴', '七', '如不服本件判決', '且符合前述得上訴之特別規定者', '得自收受判決送達之日起20日內', '向本院提出上訴書狀', '上訴於第二審法院', '中華民國109年2月25日刑事第七庭法官陳怡潔以上正本證明與原本無異', '中華民國109年2月25日書記官顧嘉文┌─────────────────────────┐│附表│├──┬───────┬──────────────┤│編號│扣案物│數量', '重量', '│├──┼───────┼──────────────┤│1│海洛因│1包', '驗餘淨重0.87公克', '│├──┼───────┼──────────────┤│2│海洛因│2包', '驗餘淨重共2公克', '│├──┼───────┼──────────────┤│3│安非他命│1包', '驗餘淨重1.1325公克', '│├──┼───────┼──────────────┤│4│毒品殘渣袋│1組│├──┼───────┼──────────────┤│5│塑膠剷管│5支│├──┼───────┼──────────────┤│6│分裝袋│1組│└──┴───────┴──────────────┘', '犯罪事實一', '郭權葳基於施用第一', '二級毒品之犯意', '於民國108年11月20日12時許', '在彰化縣鹿港鎮臺17線附近', '於其使用之汽車內', '以將海洛因與甲基安非他命置入玻璃球管內', '再以火焰燒灼玻璃球管', '使其內海洛因與甲基安非他命轉化為煙霧狀後', '以口鼻吸食之方式', '同時施用第一級毒品海洛因與第二級毒品甲基安非他命1次', '嗣於108年11月21日0時5分許', '在彰化縣鹿港鎮永康路與永寧街98巷口', '因毒品通緝案件為警查獲', '並扣得第一級毒品海洛因3包', '驗餘淨重共2.87公克', '', '第二級毒品甲基安非他命1包', '驗餘淨重1.1325公克', '', '殘渣袋1批', '分裝袋1批及塑膠鏟管5支等物', '經警採集其尿液送驗', '結果呈嗎啡', '可待因', '安非他命及甲基安非他命陽性反應', '二', '案經彰化縣警察局鹿港分局報告臺灣彰化地方檢察署檢察官偵查起訴', '理由一', '上開犯罪事實', '業經被告郭權葳於本院準備', '審理程序時坦承不諱', '且有搜索扣押筆錄', '扣押物品目錄表', '房屋租賃契約書', '蒐證照片', '扣案物照片', '毒品初步檢驗報告單', '彰化縣警察局鹿港分局尿液代號與真實姓名對照認證單', '臺灣檢驗科技股份有限公司出具之濫用藥物檢驗報告', '扣案之海洛因3包', '甲基安非他命1包', '塑膠剷管5支', '殘渣袋1組', '分裝袋1組', '法務部調查局濫用藥物實驗室鑑定書', '衛生福利部草屯療養院鑑驗書在卷可以佐證', '足見被告前揭任意性自白與事實相符', '從而', '本案事證明確', '應依法論科', '二', '核被告所為係犯毒品危害防制條例第10條第1項之施用第一級毒品罪及同條第2項之施用第二級毒品罪', '被告為施用毒品而持有第一', '二級毒品', '其持有之低度行為均應為施用之高度行為所吸收', '均不另論罪', '又被告於上開時']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "desktop = os.environ['USERPROFILE'] + '/Desktop'\n",
    "dirpath = desktop + '/drug_dataset'\n",
    "\n",
    "model = Doc2Vec.load(dirpath + \"/drug_model.bin\")\n",
    "filelist = os.listdir(dirpath)\n",
    "tmp = open(dirpath + '/label.txt', 'r', encoding = 'utf-8').readlines()\n",
    "label = {}\n",
    "train = []\n",
    "train_label = []\n",
    "\n",
    "\n",
    "for i in tqdm(tmp):\n",
    "    filename, sencnt = i.split()\n",
    "    label[filename] = sencnt\n",
    "    # print(model.infer_vector(extract_jfull(filename)))\n",
    "    # article = extract_jfull(filename)\n",
    "    # while len(article) < 300: article = article + article\n",
    "    # article = article[:300]\n",
    "    # artvec = []\n",
    "    # for i in article:\n",
    "    #     artvec.extend(model.infer_vector([i]))\n",
    "    train.append(model.infer_vector(extract_jfull(filename)))\n",
    "    train_label.append(sencnt)\n",
    "\n",
    "train = np.array(train)\n",
    "train_label = np.array(train_label)\n",
    "\n",
    "print(train.shape, train_label.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "us5XW_x6udZQ"
   },
   "source": [
    "## Create Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "Fjf5EcmJtf4e"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class DrugDataset(Dataset):\n",
    "    def __init__(self, X, y=None):\n",
    "        self.data = torch.from_numpy(X).float()\n",
    "        if y is not None:\n",
    "            y = y.astype(np.int)\n",
    "            self.label = torch.LongTensor(y)\n",
    "        else:\n",
    "            self.label = None\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.label is not None:\n",
    "            return self.data[idx], self.label[idx]\n",
    "        else:\n",
    "            return self.data[idx]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "otIC6WhGeh9v"
   },
   "source": [
    "Split the labeled data into a training set and a validation set, you can modify the variable `VAL_RATIO` to change the ratio of validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sYqi_lAuvC59",
    "outputId": "4507dc52-3083-446c-fa1a-bba22073af89"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of training set: (22202, 300)\n",
      "Size of validation set: (2467, 300)\n"
     ]
    }
   ],
   "source": [
    "VAL_RATIO = 0.1\n",
    "\n",
    "percent = int(train.shape[0] * (1 - VAL_RATIO))\n",
    "train_x, train_y, val_x, val_y = train[:percent], train_label[:percent], train[percent:], train_label[percent:]\n",
    "print('Size of training set: {}'.format(train_x.shape))\n",
    "print('Size of validation set: {}'.format(val_x.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nbCfclUIgMTX"
   },
   "source": [
    "Create a data loader from the dataset, feel free to tweak the variable `BATCH_SIZE` here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RUCbQvqJurYc",
    "outputId": "4ed55f36-131b-4aed-e171-29a936bed9de"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\terry\\AppData\\Local\\Temp/ipykernel_13716/1996969549.py:8: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y = y.astype(np.int)\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 256\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_set = DrugDataset(train_x, train_y)\n",
    "val_set = DrugDataset(val_x, val_y)\n",
    "train_loader = DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True) #only shuffle the training data\n",
    "val_loader = DataLoader(val_set, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_SY7X0lUgb50"
   },
   "source": [
    "Cleanup the unneeded variables to save memory.<br>\n",
    "\n",
    "**notes: if you need to use these variables later, then you may remove this block or clean up unneeded variables later<br>the data size is quite huge, so be aware of memory usage in colab**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IRqKNvNZwe3V"
   },
   "source": [
    "## Create Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FYr1ng5fh9pA"
   },
   "source": [
    "Define model architecture, you are encouraged to change and experiment with the model architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "id": "lbZrwT6Ny0XL"
   },
   "outputs": [],
   "source": [
    "import torch as t\n",
    "import torch.nn as nn\n",
    "\n",
    "class LSTM(nn.Module):\n",
    "#建立LSTM class\n",
    "    def __init__(self, input_dim = 300, hidden_dim = 512, layer_dim = 4, output_dim = 1):\n",
    "        super(LSTM,self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.layer_dim = layer_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, layer_dim, batch_first = True, dropout = 0.5, bidirectional = True)\n",
    "        self.linear = nn.Linear(hidden_dim * 2, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, _ = self.lstm(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VRYciXZvPbYh"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "id": "y114Vmm3Ja6o"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "#check device\n",
    "def get_device():\n",
    "    return 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device = get_device()\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KbBcBXkSp6RA"
   },
   "source": [
    "Feel free to change the training parameters here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 375
    },
    "id": "QTp3ZXg1yO9Y",
    "outputId": "ff6221ce-72b8-4b2a-8872-f52a13c49752",
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_13716/725689679.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLSTM\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'best_weight.pth'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'best_weight.pth'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\terry\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36mto\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    905\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    906\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 907\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    908\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    909\u001b[0m     def register_backward_hook(\n",
      "\u001b[1;32mc:\\Users\\terry\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    576\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    577\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 578\u001b[1;33m             \u001b[0mmodule\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    579\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    580\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\terry\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\rnn.py\u001b[0m in \u001b[0;36m_apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    180\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    181\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 182\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mRNNBase\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    183\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m         \u001b[1;31m# Resets _flat_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\terry\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_apply\u001b[1;34m(self, fn)\u001b[0m\n\u001b[0;32m    599\u001b[0m             \u001b[1;31m# `with torch.no_grad():`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    600\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 601\u001b[1;33m                 \u001b[0mparam_applied\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    602\u001b[0m             \u001b[0mshould_use_set_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    603\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\terry\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36mconvert\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m    903\u001b[0m                 return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None,\n\u001b[0;32m    904\u001b[0m                             non_blocking, memory_format=convert_to_format)\n\u001b[1;32m--> 905\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    906\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    907\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1."
     ]
    }
   ],
   "source": [
    "model = LSTM().to(device)\n",
    "model.device = device\n",
    "if os.path.exists('best_weight.pth'):\n",
    "    try:\n",
    "        model.load_state_dict(torch.load('best_weight.pth'))\n",
    "    except: \n",
    "        print('Failed to load the model weight!')\n",
    "\n",
    "# For the classification task, we use cross-entropy as the measurement of performance.\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 3e-4, weight_decay = 1e-5)\n",
    "\n",
    "# The number of training epochs.\n",
    "n_epochs = 100\n",
    "do_semi = True\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    model.train()\n",
    "    train_loss = []\n",
    "    train_accs = []\n",
    "\n",
    "    # Iterate the training set by batches.\n",
    "    for batch in tqdm(train_loader):\n",
    "        imgs, labels = batch\n",
    "        logits = model(imgs.to(device))\n",
    "        loss = criterion(logits, labels.to(device))\n",
    "\n",
    "        # Gradients stored in the parameters in the previous step should be cleared out first.\n",
    "        optimizer.zero_grad()\n",
    "        # Compute the gradients for parameters.\n",
    "        loss.backward()\n",
    "        grad_norm = nn.utils.clip_grad_norm_(model.parameters(), max_norm=10)\n",
    "        optimizer.step()\n",
    "        acc = (logits == labels.to(device)).float().mean()\n",
    "\n",
    "        # Record the loss and accuracy.\n",
    "        train_loss.append(loss.item())\n",
    "        train_accs.append(acc)\n",
    "\n",
    "    # The average loss and accuracy of the training set is the average of the recorded values.\n",
    "    train_loss = sum(train_loss) / len(train_loss)\n",
    "    train_acc = sum(train_accs) / len(train_accs)\n",
    "\n",
    "    # ---------- Validation ----------\n",
    "    # Make sure the model is in eval mode so that some modules like dropout are disabled and work normally.\n",
    "    model.eval()\n",
    "\n",
    "    # These are used to record information in validation.\n",
    "    valid_loss = []\n",
    "    valid_accs = []\n",
    "\n",
    "    # Iterate the validation set by batches.\n",
    "    for batch in tqdm(val_loader):\n",
    "        imgs, labels = batch\n",
    "        with torch.no_grad():\n",
    "          logits = model(imgs.to(device))\n",
    "        loss = criterion(logits, labels.to(device))\n",
    "        acc = (logits.argmax(dim=-1) == labels.to(device)).float().mean()\n",
    "        valid_loss.append(loss.item())\n",
    "        valid_accs.append(acc)\n",
    "\n",
    "    # The average loss and accuracy for entire validation set is the average of the recorded values.\n",
    "    valid_loss = sum(valid_loss) / len(valid_loss)\n",
    "    valid_acc = sum(valid_accs) / len(valid_accs)\n",
    "    best_acc = 0\n",
    "    \n",
    "    if valid_acc > best_acc:\n",
    "        best_model = model\n",
    "        best_acc = valid_acc\n",
    "        torch.save(model.state_dict(), \"best_weight.pth\")\n",
    "\n",
    "    # Print the information.\n",
    "    print(f\"[ Train | {epoch + 1:03d}/{n_epochs:03d} ] loss = {train_loss:.5f}, acc = {train_acc:.5f}\")\n",
    "    print(f\"[ Valid | {epoch + 1:03d}/{n_epochs:03d} ] loss = {valid_loss:.5f}, acc = {valid_acc:.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1Hi7jTn3PX-m"
   },
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NfUECMFCn5VG"
   },
   "source": [
    "Create a testing dataset, and load model from the saved checkpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "1PKjtAScPWtr"
   },
   "outputs": [],
   "source": [
    "# create testing dataset\n",
    "test_set = DrugDataset(val_x)\n",
    "test_loader = DataLoader(test_set, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "940TtCCdoYd0"
   },
   "source": [
    "Make prediction and output the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "84HU5GGjPqR0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [00:00<00:00,  9.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4]\n",
      "[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4]\n",
      "[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4]\n",
      "[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4]\n",
      "[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4]\n",
      "[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 13.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4]\n",
      "[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4]\n",
      "[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4]\n",
      "[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "predict = []\n",
    "model.eval() # set the model to evaluation mode\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(test_loader):\n",
    "        imgs = batch\n",
    "        with torch.no_grad():\n",
    "            logits = model(imgs.to(device))\n",
    "            answer = logits.argmax(dim=-1).cpu().numpy().tolist()\n",
    "            predict.extend(answer)\n",
    "            print(answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "HlDK3mMJgwEj"
   },
   "outputs": [],
   "source": [
    "# put the result to csv\n",
    "\n",
    "with open(desktop + '/prediction.csv', 'w') as f:\n",
    "    f.write('Id,Class\\n')\n",
    "    for i, y in enumerate(predict):\n",
    "        f.write('{},{}\\n'.format(i, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Copy of MLSpring22_HW2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "3e06028060a7864164bfee2227bae8dfd39c60041c455d9e6b5a8dd3aec9b09f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
